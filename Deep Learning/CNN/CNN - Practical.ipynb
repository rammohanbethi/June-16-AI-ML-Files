{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying image data generator class for training images\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                zoom_range=0.2,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply for test set\n",
    "test_datagen=ImageDataGenerator(rescale=1./255) #0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to set the image width and height\n",
    "img_width = 128\n",
    "img_height= 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 269 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#applying datagenerator on our training and testing images (original images)\n",
    "x_train=train_datagen.flow_from_directory(r'./Dataset/Train',\n",
    "                                 target_size=(img_width,img_height),\n",
    "                                 batch_size=16,\n",
    "                                 class_mode='binary') #categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#applying datagenerator on our training and testing images (original images)\n",
    "x_test=test_datagen.flow_from_directory(r'./Dataset/Test',\n",
    "                                 target_size=(img_width,img_height),\n",
    "                                 batch_size=16,\n",
    "                                 class_mode='binary') #categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "#cnn, c,p,f,f(nn)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D #Covn2D #256,256,3\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding cnn layers\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(img_width,img_height,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add(Convolution2D(64,(3,3),input_shape=(img_width,img_height,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1, 1), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 508032)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=270))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=135))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideen layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='sigmoid',units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 44s 2s/step - loss: 0.7051 - accuracy: 0.4693 - val_loss: 0.6915 - val_accuracy: 0.5208\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.6917 - accuracy: 0.5408 - val_loss: 0.6882 - val_accuracy: 0.5208\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.6879 - accuracy: 0.5461 - val_loss: 0.6840 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 0.6799 - val_accuracy: 0.5417\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.6836 - accuracy: 0.5856 - val_loss: 0.6738 - val_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(x_train,epochs=5,\n",
    "                              steps_per_epoch=269//16,\n",
    "                              validation_data=x_test,\n",
    "                              validation_steps=55//16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('animal.h5') #HDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
